---
description: A provider for integrating with OpenAI models.
labels: ['AI', 'provider', 'OpenAI']
---

### Basic Text Generation

Demonstrates how to use the OpenAI provider to generate a simple text response from a user prompt.

```typescript
// Replace with your actual OpenAI API key or ensure it is set as an environment variable (OPENAI_API_KEY)
const openai = new OpenAiProvider('YOUR_OPENAI_API_KEY');
const request: AiModelRequest = {
  prompt: 'What is the capital of France?',
  model: 'gpt-3.5-turbo',
};
openai.request(request)
  .then(response => {
    console.log('Generated Text:', response.text);
  })
  .catch(error => {
    console.error('Error during AI request:', error);
  });
```

### Streaming Text Generation

Shows how to use the OpenAI provider to handle streaming responses, receiving chunks of text as they are generated.

```typescript
const openai = new OpenAiProvider('YOUR_OPENAI_API_KEY');
let fullResponse = '';
const streamHandler = (chunk: string) => {
  fullResponse += chunk;
  process.stdout.write(chunk); // Log chunks as they arrive
};
const request: AiModelRequest = {
  prompt: 'Tell me a short story about a space-faring cat.',
  model: 'gpt-3.5-turbo',
  stream: streamHandler,
};
openai.request(request)
  .then(response => {
    console.log('\n--- Stream Complete ---');
    console.log('Final Response:', response.text);
    // You can also use 'fullResponse' directly here if you aggregated it
  })
  .catch(error => {
    console.error('Error during streaming AI request:', error);
  });
```

### Customizing Model and System Prompt

Illustrates how to specify a different model and include a system prompt for guiding the AI behavior.

```typescript
const openai = new OpenAiProvider('YOUR_OPENAI_API_KEY');
const request: AiModelRequest = {
  prompt: 'Describe the benefits of modular software design.',
  model: 'gpt-4', // Using a more advanced model
  systemPrompt: 'You are a senior software architect. Provide concise and clear explanations.', // Guiding the AI persona
  options: {
    temperature: 0.7, // Adjusting generation randomness
    max_tokens: 150, // Limiting response length
  },
};
openai.request(request)
  .then(response => {
    console.log('Architect AI Response:', response.text);
  })
  .catch(error => {
    console.error('Error with custom AI request:', error);
  });